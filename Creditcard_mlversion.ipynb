{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3698a317-9714-4b4f-9c9b-5171d76b3062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: matplotlib in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (3.10.1)\n",
      "Requirement already satisfied: seaborn in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (0.13.2)\n",
      "Requirement already satisfied: plotly in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (6.0.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (2.2.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from plotly) (1.30.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: matplotlib in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (3.10.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (2.1.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (3.6.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.19.0-cp312-cp312-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.2.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (24.1)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 (from tensorflow)\n",
      "  Using cached protobuf-5.29.4-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (75.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (4.12.2)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Downloading wrapt-1.17.2-cp312-cp312-win_amd64.whl.metadata (6.5 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Using cached grpcio-1.71.0-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard~=2.19.0 (from tensorflow)\n",
      "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow)\n",
      "  Downloading keras-3.9.2-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (2.1.3)\n",
      "Collecting h5py>=3.11.0 (from tensorflow)\n",
      "  Downloading h5py-3.13.0-cp312-cp312-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting ml-dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.5.1-cp312-cp312-win_amd64.whl.metadata (22 kB)\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow)\n",
      "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting rich (from keras>=3.5.0->tensorflow)\n",
      "  Downloading rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow)\n",
      "  Downloading namex-0.0.9-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow)\n",
      "  Downloading optree-0.15.0-cp312-cp312-win_amd64.whl.metadata (49 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Downloading markdown-3.8-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.5.0->tensorflow)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\asus\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading tensorflow-2.19.0-cp312-cp312-win_amd64.whl (376.0 MB)\n",
      "   ---------------------------------------- 0.0/376.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.4/376.0 MB 13.4 MB/s eta 0:00:28\n",
      "    --------------------------------------- 6.3/376.0 MB 17.5 MB/s eta 0:00:22\n",
      "   - -------------------------------------- 10.5/376.0 MB 18.2 MB/s eta 0:00:21\n",
      "   - -------------------------------------- 14.9/376.0 MB 18.8 MB/s eta 0:00:20\n",
      "   - -------------------------------------- 18.1/376.0 MB 18.4 MB/s eta 0:00:20\n",
      "   -- ------------------------------------- 22.0/376.0 MB 18.3 MB/s eta 0:00:20\n",
      "   -- ------------------------------------- 27.5/376.0 MB 19.6 MB/s eta 0:00:18\n",
      "   --- ------------------------------------ 34.6/376.0 MB 21.3 MB/s eta 0:00:17\n",
      "   ---- ----------------------------------- 41.2/376.0 MB 22.6 MB/s eta 0:00:15\n",
      "   ----- ---------------------------------- 47.7/376.0 MB 23.5 MB/s eta 0:00:14\n",
      "   ----- ---------------------------------- 54.3/376.0 MB 24.2 MB/s eta 0:00:14\n",
      "   ------ --------------------------------- 60.8/376.0 MB 24.8 MB/s eta 0:00:13\n",
      "   ------- -------------------------------- 67.4/376.0 MB 25.3 MB/s eta 0:00:13\n",
      "   ------- -------------------------------- 70.5/376.0 MB 24.6 MB/s eta 0:00:13\n",
      "   ------- -------------------------------- 72.4/376.0 MB 23.5 MB/s eta 0:00:13\n",
      "   ------- -------------------------------- 74.4/376.0 MB 22.7 MB/s eta 0:00:14\n",
      "   -------- ------------------------------- 77.1/376.0 MB 22.0 MB/s eta 0:00:14\n",
      "   -------- ------------------------------- 78.6/376.0 MB 21.2 MB/s eta 0:00:15\n",
      "   -------- ------------------------------- 81.0/376.0 MB 20.7 MB/s eta 0:00:15\n",
      "   -------- ------------------------------- 82.3/376.0 MB 20.0 MB/s eta 0:00:15\n",
      "   -------- ------------------------------- 83.9/376.0 MB 19.5 MB/s eta 0:00:16\n",
      "   --------- ------------------------------ 86.0/376.0 MB 19.0 MB/s eta 0:00:16\n",
      "   --------- ------------------------------ 88.1/376.0 MB 18.6 MB/s eta 0:00:16\n",
      "   --------- ------------------------------ 89.7/376.0 MB 18.2 MB/s eta 0:00:16\n",
      "   --------- ------------------------------ 90.7/376.0 MB 17.6 MB/s eta 0:00:17\n",
      "   --------- ------------------------------ 92.3/376.0 MB 17.3 MB/s eta 0:00:17\n",
      "   ---------- ----------------------------- 94.1/376.0 MB 16.9 MB/s eta 0:00:17\n",
      "   ---------- ----------------------------- 95.4/376.0 MB 16.6 MB/s eta 0:00:17\n",
      "   ---------- ----------------------------- 97.5/376.0 MB 16.2 MB/s eta 0:00:18\n",
      "   ---------- ----------------------------- 99.4/376.0 MB 16.1 MB/s eta 0:00:18\n",
      "   ---------- ---------------------------- 100.9/376.0 MB 15.8 MB/s eta 0:00:18\n",
      "   ---------- ---------------------------- 103.5/376.0 MB 15.7 MB/s eta 0:00:18\n",
      "   ---------- ---------------------------- 105.9/376.0 MB 15.6 MB/s eta 0:00:18\n",
      "   ----------- --------------------------- 107.7/376.0 MB 15.4 MB/s eta 0:00:18\n",
      "   ----------- --------------------------- 108.8/376.0 MB 15.2 MB/s eta 0:00:18\n",
      "   ----------- --------------------------- 111.4/376.0 MB 15.0 MB/s eta 0:00:18\n",
      "   ----------- --------------------------- 113.2/376.0 MB 14.9 MB/s eta 0:00:18\n",
      "   ----------- --------------------------- 115.3/376.0 MB 14.8 MB/s eta 0:00:18\n",
      "   ------------ -------------------------- 116.9/376.0 MB 14.6 MB/s eta 0:00:18\n",
      "   ------------ -------------------------- 118.0/376.0 MB 14.3 MB/s eta 0:00:19\n",
      "   ------------ -------------------------- 119.3/376.0 MB 14.2 MB/s eta 0:00:19\n",
      "   ------------ -------------------------- 122.2/376.0 MB 14.1 MB/s eta 0:00:18\n",
      "   ------------ -------------------------- 124.5/376.0 MB 14.1 MB/s eta 0:00:18\n",
      "   ------------- ------------------------- 126.9/376.0 MB 14.0 MB/s eta 0:00:18\n",
      "   ------------- ------------------------- 129.8/376.0 MB 14.0 MB/s eta 0:00:18\n",
      "   ------------- ------------------------- 133.2/376.0 MB 14.0 MB/s eta 0:00:18\n",
      "   -------------- ------------------------ 137.6/376.0 MB 14.2 MB/s eta 0:00:17\n",
      "   -------------- ------------------------ 141.6/376.0 MB 14.3 MB/s eta 0:00:17\n",
      "   --------------- ----------------------- 144.7/376.0 MB 14.3 MB/s eta 0:00:17\n",
      "   --------------- ----------------------- 149.4/376.0 MB 14.5 MB/s eta 0:00:16\n",
      "   --------------- ----------------------- 152.6/376.0 MB 14.5 MB/s eta 0:00:16\n",
      "   ---------------- ---------------------- 157.0/376.0 MB 14.6 MB/s eta 0:00:15\n",
      "   ---------------- ---------------------- 162.0/376.0 MB 14.8 MB/s eta 0:00:15\n",
      "   ----------------- --------------------- 167.0/376.0 MB 15.0 MB/s eta 0:00:14\n",
      "   ----------------- --------------------- 171.2/376.0 MB 15.1 MB/s eta 0:00:14\n",
      "   ------------------ -------------------- 175.1/376.0 MB 15.2 MB/s eta 0:00:14\n",
      "   ------------------ -------------------- 178.5/376.0 MB 15.2 MB/s eta 0:00:14\n",
      "   ------------------ -------------------- 182.2/376.0 MB 15.2 MB/s eta 0:00:13\n",
      "   ------------------- ------------------- 185.1/376.0 MB 15.2 MB/s eta 0:00:13\n",
      "   ------------------- ------------------- 189.3/376.0 MB 15.3 MB/s eta 0:00:13\n",
      "   -------------------- ------------------ 193.2/376.0 MB 15.4 MB/s eta 0:00:12\n",
      "   -------------------- ------------------ 198.2/376.0 MB 15.5 MB/s eta 0:00:12\n",
      "   -------------------- ------------------ 201.1/376.0 MB 15.5 MB/s eta 0:00:12\n",
      "   --------------------- ----------------- 203.4/376.0 MB 15.4 MB/s eta 0:00:12\n",
      "   --------------------- ----------------- 205.5/376.0 MB 15.3 MB/s eta 0:00:12\n",
      "   --------------------- ----------------- 207.1/376.0 MB 15.2 MB/s eta 0:00:12\n",
      "   --------------------- ----------------- 209.7/376.0 MB 15.2 MB/s eta 0:00:11\n",
      "   ---------------------- ---------------- 212.3/376.0 MB 15.2 MB/s eta 0:00:11\n",
      "   ---------------------- ---------------- 215.0/376.0 MB 15.1 MB/s eta 0:00:11\n",
      "   ---------------------- ---------------- 218.4/376.0 MB 15.1 MB/s eta 0:00:11\n",
      "   ---------------------- ---------------- 221.2/376.0 MB 15.1 MB/s eta 0:00:11\n",
      "   ----------------------- --------------- 223.6/376.0 MB 15.1 MB/s eta 0:00:11\n",
      "   ----------------------- --------------- 226.0/376.0 MB 15.0 MB/s eta 0:00:10\n",
      "   ----------------------- --------------- 227.3/376.0 MB 14.9 MB/s eta 0:00:10\n",
      "   ----------------------- --------------- 229.1/376.0 MB 14.8 MB/s eta 0:00:10\n",
      "   ----------------------- --------------- 231.2/376.0 MB 14.8 MB/s eta 0:00:10\n",
      "   ------------------------ -------------- 233.3/376.0 MB 14.7 MB/s eta 0:00:10\n",
      "   ------------------------ -------------- 234.9/376.0 MB 14.6 MB/s eta 0:00:10\n",
      "   ------------------------ -------------- 237.0/376.0 MB 14.6 MB/s eta 0:00:10\n",
      "   ------------------------ -------------- 239.9/376.0 MB 14.5 MB/s eta 0:00:10\n",
      "   ------------------------- ------------- 244.1/376.0 MB 14.6 MB/s eta 0:00:10\n",
      "   ------------------------- ------------- 247.2/376.0 MB 14.6 MB/s eta 0:00:09\n",
      "   -------------------------- ------------ 250.9/376.0 MB 14.7 MB/s eta 0:00:09\n",
      "   -------------------------- ------------ 254.0/376.0 MB 14.7 MB/s eta 0:00:09\n",
      "   -------------------------- ------------ 257.4/376.0 MB 14.7 MB/s eta 0:00:09\n",
      "   --------------------------- ----------- 261.9/376.0 MB 14.8 MB/s eta 0:00:08\n",
      "   --------------------------- ----------- 266.1/376.0 MB 14.8 MB/s eta 0:00:08\n",
      "   ---------------------------- ---------- 270.3/376.0 MB 14.9 MB/s eta 0:00:08\n",
      "   ---------------------------- ---------- 275.3/376.0 MB 14.9 MB/s eta 0:00:07\n",
      "   ----------------------------- --------- 280.2/376.0 MB 14.9 MB/s eta 0:00:07\n",
      "   ----------------------------- --------- 285.5/376.0 MB 15.0 MB/s eta 0:00:07\n",
      "   ------------------------------ -------- 293.1/376.0 MB 15.0 MB/s eta 0:00:06\n",
      "   ------------------------------ -------- 297.8/376.0 MB 15.0 MB/s eta 0:00:06\n",
      "   ------------------------------- ------- 301.7/376.0 MB 14.9 MB/s eta 0:00:05\n",
      "   ------------------------------- ------- 305.4/376.0 MB 14.8 MB/s eta 0:00:05\n",
      "   -------------------------------- ------ 309.1/376.0 MB 14.7 MB/s eta 0:00:05\n",
      "   -------------------------------- ------ 313.3/376.0 MB 14.7 MB/s eta 0:00:05\n",
      "   --------------------------------- ----- 319.3/376.0 MB 14.7 MB/s eta 0:00:04\n",
      "   --------------------------------- ----- 324.8/376.0 MB 14.6 MB/s eta 0:00:04\n",
      "   ---------------------------------- ---- 330.0/376.0 MB 14.6 MB/s eta 0:00:04\n",
      "   ---------------------------------- ---- 335.0/376.0 MB 14.8 MB/s eta 0:00:03\n",
      "   ----------------------------------- --- 339.7/376.0 MB 15.0 MB/s eta 0:00:03\n",
      "   ----------------------------------- --- 343.9/376.0 MB 15.3 MB/s eta 0:00:03\n",
      "   ------------------------------------ -- 348.9/376.0 MB 15.6 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 352.6/376.0 MB 15.9 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 357.6/376.0 MB 16.3 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 363.3/376.0 MB 16.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  367.8/376.0 MB 16.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  372.5/376.0 MB 17.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  375.9/376.0 MB 17.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  375.9/376.0 MB 17.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  375.9/376.0 MB 17.5 MB/s eta 0:00:01\n",
      "   --------------------------------------- 376.0/376.0 MB 16.8 MB/s eta 0:00:00\n",
      "Downloading absl_py-2.2.2-py3-none-any.whl (135 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Using cached grpcio-1.71.0-cp312-cp312-win_amd64.whl (4.3 MB)\n",
      "Downloading h5py-3.13.0-cp312-cp312-win_amd64.whl (3.0 MB)\n",
      "   ---------------------------------------- 0.0/3.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 3.0/3.0 MB 19.2 MB/s eta 0:00:00\n",
      "Downloading keras-3.9.2-py3-none-any.whl (1.3 MB)\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.3/1.3 MB 13.8 MB/s eta 0:00:00\n",
      "Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "   ---------------------------------------- 0.0/26.4 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 5.2/26.4 MB 26.6 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 12.3/26.4 MB 30.8 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 18.9/26.4 MB 31.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 25.4/26.4 MB 31.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.4/26.4 MB 29.4 MB/s eta 0:00:00\n",
      "Downloading ml_dtypes-0.5.1-cp312-cp312-win_amd64.whl (210 kB)\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Using cached protobuf-5.29.4-cp310-abi3-win_amd64.whl (434 kB)\n",
      "Downloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 5.5/5.5 MB 30.7 MB/s eta 0:00:00\n",
      "Downloading termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading wrapt-1.17.2-cp312-cp312-win_amd64.whl (38 kB)\n",
      "Downloading markdown-3.8-py3-none-any.whl (106 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Downloading namex-0.0.9-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.15.0-cp312-cp312-win_amd64.whl (307 kB)\n",
      "Downloading rich-14.0.0-py3-none-any.whl (243 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, wheel, termcolor, tensorboard-data-server, protobuf, optree, opt-einsum, ml-dtypes, mdurl, markdown, h5py, grpcio, google-pasta, gast, absl-py, tensorboard, markdown-it-py, astunparse, rich, keras, tensorflow\n",
      "Successfully installed absl-py-2.2.2 astunparse-1.6.3 flatbuffers-25.2.10 gast-0.6.0 google-pasta-0.2.0 grpcio-1.71.0 h5py-3.13.0 keras-3.9.2 libclang-18.1.1 markdown-3.8 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.5.1 namex-0.0.9 opt-einsum-3.4.0 optree-0.15.0 protobuf-5.29.4 rich-14.0.0 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorflow-2.19.0 termcolor-3.1.0 wheel-0.45.1 wrapt-1.17.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install matplotlib seaborn plotly pandas\n",
    "!pip install matplotlib\n",
    "!pip install scikit-learn\n",
    "!pip install tensorflow\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3302408-ff98-4c52-9e4a-ab7236c32f8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc5bb5ee-2b49-49b8-80f8-286570d26038",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bc76ba7-4cfc-4e13-a587-8c5eb8ef4bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V13       V14  \\\n",
       "0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169   \n",
       "1  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772   \n",
       "2  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946   \n",
       "3  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924   \n",
       "4 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670   \n",
       "\n",
       "        V15       V16       V17       V18       V19       V20       V21  \\\n",
       "0  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307   \n",
       "1  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775   \n",
       "2  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998   \n",
       "3 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300   \n",
       "4  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "\n",
       "   Amount  Class  \n",
       "0  149.62      0  \n",
       "1    2.69      0  \n",
       "2  378.66      0  \n",
       "3  123.50      0  \n",
       "4   69.99      0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "828550c2-0021-4bbb-aef2-5b7df14ee1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06b0cbd5-2f2f-4a51-babc-4a1e08fd53a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V13       V14  \\\n",
       "0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169   \n",
       "1  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772   \n",
       "2  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946   \n",
       "3  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924   \n",
       "4 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670   \n",
       "\n",
       "        V15       V16       V17       V18       V19       V20       V21  \\\n",
       "0  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307   \n",
       "1  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775   \n",
       "2  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998   \n",
       "3 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300   \n",
       "4  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "\n",
       "   Amount  Class  \n",
       "0  149.62      0  \n",
       "1    2.69      0  \n",
       "2  378.66      0  \n",
       "3  123.50      0  \n",
       "4   69.99      0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7a4c2ca-2afc-4716-9e31-3b4e13bbf163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>172786.0</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>4.356170</td>\n",
       "      <td>-1.593105</td>\n",
       "      <td>2.711941</td>\n",
       "      <td>-0.689256</td>\n",
       "      <td>4.626942</td>\n",
       "      <td>-0.924459</td>\n",
       "      <td>1.107641</td>\n",
       "      <td>1.991691</td>\n",
       "      <td>0.510632</td>\n",
       "      <td>-0.682920</td>\n",
       "      <td>1.475829</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>172787.0</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>-0.975926</td>\n",
       "      <td>-0.150189</td>\n",
       "      <td>0.915802</td>\n",
       "      <td>1.214756</td>\n",
       "      <td>-0.675143</td>\n",
       "      <td>1.164931</td>\n",
       "      <td>-0.711757</td>\n",
       "      <td>-0.025693</td>\n",
       "      <td>-1.221179</td>\n",
       "      <td>-1.545556</td>\n",
       "      <td>0.059616</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>-0.484782</td>\n",
       "      <td>0.411614</td>\n",
       "      <td>0.063119</td>\n",
       "      <td>-0.183699</td>\n",
       "      <td>-0.510602</td>\n",
       "      <td>1.329284</td>\n",
       "      <td>0.140716</td>\n",
       "      <td>0.313502</td>\n",
       "      <td>0.395652</td>\n",
       "      <td>-0.577252</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>-0.399126</td>\n",
       "      <td>-1.933849</td>\n",
       "      <td>-0.962886</td>\n",
       "      <td>-1.042082</td>\n",
       "      <td>0.449624</td>\n",
       "      <td>1.962563</td>\n",
       "      <td>-0.608577</td>\n",
       "      <td>0.509928</td>\n",
       "      <td>1.113981</td>\n",
       "      <td>2.897849</td>\n",
       "      <td>0.127434</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>172792.0</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>-0.915427</td>\n",
       "      <td>-1.040458</td>\n",
       "      <td>-0.031513</td>\n",
       "      <td>-0.188093</td>\n",
       "      <td>-0.084316</td>\n",
       "      <td>0.041333</td>\n",
       "      <td>-0.302620</td>\n",
       "      <td>-0.660377</td>\n",
       "      <td>0.167430</td>\n",
       "      <td>-0.256117</td>\n",
       "      <td>0.382948</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2        V3        V4        V5  \\\n",
       "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
       "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
       "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
       "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
       "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
       "\n",
       "              V6        V7        V8        V9       V10       V11       V12  \\\n",
       "284802 -2.606837 -4.918215  7.305334  1.914428  4.356170 -1.593105  2.711941   \n",
       "284803  1.058415  0.024330  0.294869  0.584800 -0.975926 -0.150189  0.915802   \n",
       "284804  3.031260 -0.296827  0.708417  0.432454 -0.484782  0.411614  0.063119   \n",
       "284805  0.623708 -0.686180  0.679145  0.392087 -0.399126 -1.933849 -0.962886   \n",
       "284806 -0.649617  1.577006 -0.414650  0.486180 -0.915427 -1.040458 -0.031513   \n",
       "\n",
       "             V13       V14       V15       V16       V17       V18       V19  \\\n",
       "284802 -0.689256  4.626942 -0.924459  1.107641  1.991691  0.510632 -0.682920   \n",
       "284803  1.214756 -0.675143  1.164931 -0.711757 -0.025693 -1.221179 -1.545556   \n",
       "284804 -0.183699 -0.510602  1.329284  0.140716  0.313502  0.395652 -0.577252   \n",
       "284805 -1.042082  0.449624  1.962563 -0.608577  0.509928  1.113981  2.897849   \n",
       "284806 -0.188093 -0.084316  0.041333 -0.302620 -0.660377  0.167430 -0.256117   \n",
       "\n",
       "             V20       V21       V22       V23       V24       V25       V26  \\\n",
       "284802  1.475829  0.213454  0.111864  1.014480 -0.509348  1.436807  0.250034   \n",
       "284803  0.059616  0.214205  0.924384  0.012463 -1.016226 -0.606624 -0.395255   \n",
       "284804  0.001396  0.232045  0.578229 -0.037501  0.640134  0.265745 -0.087371   \n",
       "284805  0.127434  0.265245  0.800049 -0.163298  0.123205 -0.569159  0.546668   \n",
       "284806  0.382948  0.261057  0.643078  0.376777  0.008797 -0.473649 -0.818267   \n",
       "\n",
       "             V27       V28  Amount  Class  \n",
       "284802  0.943651  0.823731    0.77      0  \n",
       "284803  0.068472 -0.053527   24.79      0  \n",
       "284804  0.004455 -0.026561   67.88      0  \n",
       "284805  0.108821  0.104533   10.00      0  \n",
       "284806 -0.002415  0.013649  217.00      0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91529441-4937-4eee-9b73-20abba513b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb34a319-5d53-4736-8851-a0422e1a1f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns : 31\n",
      "Number of rows : 284807\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of columns : {}\".format(data.shape[1]))\n",
    "print(\"Number of rows : {}\".format(data.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30072af6-efa2-40d1-bca4-c838c41aef1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4165d011-9f25-4a31-b7b1-b0f2a7fe5a08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d4d908ef-a5c9-49c6-b26c-a3d749a95de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0bf61df5-bc3d-4d10-93fc-6442ea4883b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "data['Amount'] = sc.fit_transform(pd.DataFrame(data['Amount']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "93fc6933-377c-407b-a862-2cf9c21e651d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0.233169</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>-0.347092</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>1.137702</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0.130015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>-0.081308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V13       V14  \\\n",
       "0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169   \n",
       "1  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772   \n",
       "2  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946   \n",
       "3  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924   \n",
       "4 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670   \n",
       "\n",
       "        V15       V16       V17       V18       V19       V20       V21  \\\n",
       "0  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307   \n",
       "1  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775   \n",
       "2  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998   \n",
       "3 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300   \n",
       "4  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "\n",
       "     Amount  Class  \n",
       "0  0.233169      0  \n",
       "1 -0.347092      0  \n",
       "2  1.137702      0  \n",
       "3  0.130015      0  \n",
       "4 -0.081308      0  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5390d62d-103d-497d-860c-a2cab49a5561",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['Time'] , axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "01c81a28-5f6a-4a13-817b-8945fb008d6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0.244964</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>-0.342475</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>1.160686</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0.140534</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>-0.073403</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V13       V14  \\\n",
       "0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169   \n",
       "1  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772   \n",
       "2  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946   \n",
       "3  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924   \n",
       "4 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670   \n",
       "\n",
       "        V15       V16       V17       V18       V19       V20       V21  \\\n",
       "0  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307   \n",
       "1  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775   \n",
       "2  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998   \n",
       "3 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300   \n",
       "4  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "\n",
       "     Amount  Class  \n",
       "0  0.244964      0  \n",
       "1 -0.342475      0  \n",
       "2  1.160686      0  \n",
       "3  0.140534      0  \n",
       "4 -0.073403      0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93e0aa5e-237d-4364-8747-997068c07042",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.True_"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c726fac-399d-4353-83c0-ab3f52b57e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed05fd64-dd23-4eb5-a8df-4b37bf366ad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(275663, 30)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c6914897-7220-4fdb-8f27-b8b7c451dfb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    275190\n",
       "1       473\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9869c2a4-7d98-4881-bb15-68950193b660",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aa48ba01-7a00-491b-837b-40d94a6a6b0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='Class', data=data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "10e6b006-7e37-422e-8f9b-baf0bcf9a983",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('Class' , axis = 1)\n",
    "Y = data['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4c8cbe4c-982c-4e92-916e-b52554a1c4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "406c7d46-fc99-46a0-9aa5-8408ffef5f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train , X_test , Y_train , Y_test = train_test_split(X , Y , test_size = 0.2 , random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efeeaca8-85cf-4263-8271-8256e154756d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41412971-2591-46a4-881a-767e1320c53c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m model = Sequential([\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     Dense(\u001b[32m64\u001b[39m, input_dim=\u001b[43mX_train\u001b[49m.shape[\u001b[32m1\u001b[39m], activation=\u001b[33m'\u001b[39m\u001b[33mrelu\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m      3\u001b[39m     Dropout(\u001b[32m0.3\u001b[39m),\n\u001b[32m      4\u001b[39m     Dense(\u001b[32m32\u001b[39m, activation=\u001b[33m'\u001b[39m\u001b[33mrelu\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m      5\u001b[39m     Dropout(\u001b[32m0.3\u001b[39m),\n\u001b[32m      6\u001b[39m     Dense(\u001b[32m1\u001b[39m, activation=\u001b[33m'\u001b[39m\u001b[33msigmoid\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      7\u001b[39m ])\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Compile the model\u001b[39;00m\n\u001b[32m     10\u001b[39m model.compile(optimizer=Adam(learning_rate=\u001b[32m0.001\u001b[39m), loss=\u001b[33m'\u001b[39m\u001b[33mbinary_crossentropy\u001b[39m\u001b[33m'\u001b[39m, metrics=[\u001b[33m'\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m'\u001b[39m, tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
      "\u001b[31mNameError\u001b[39m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(64, input_dim=X_train.shape[1], activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, Y_train, epochs=20, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccfaac2-0e37-4fe0-9d57-82cc81be7f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "loss, accuracy, precision, recall = model.evaluate(X_test, Y_test)\n",
    "f1_score_dl = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "print(f\"\\nAccuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1_score_dl}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "acd07099-f183-4c2c-9193-58c7e09952f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#undersampling \n",
    "normal = data[data['Class'] == 0 ]\n",
    "fraud = data[data['Class'] == 1 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ddc5705a-2d39-4f33-9071-c5e6cd8f734d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(275190, 30)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2716a9da-1370-4e8b-b27b-f2da8ad082b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(473, 30)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "802e19b8-900f-4346-87cf-484125997a41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#taking \n",
    "normal_sample = normal.sample(n = 473)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8f170381-b308-4cb8-85b5-2f8575658da0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(473, 30)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7023e087-e635-4995-ac3a-96f016c58cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.concat([normal_sample , fraud] , ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cdbeba1b-13b9-4198-9e32-91661f801d68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.572468</td>\n",
       "      <td>0.278829</td>\n",
       "      <td>0.357892</td>\n",
       "      <td>-1.432970</td>\n",
       "      <td>-0.106104</td>\n",
       "      <td>1.643718</td>\n",
       "      <td>-0.509810</td>\n",
       "      <td>0.763207</td>\n",
       "      <td>-0.937081</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>-0.741923</td>\n",
       "      <td>-0.203978</td>\n",
       "      <td>0.674906</td>\n",
       "      <td>-0.337470</td>\n",
       "      <td>0.491004</td>\n",
       "      <td>-0.197214</td>\n",
       "      <td>1.496023</td>\n",
       "      <td>-2.785659</td>\n",
       "      <td>1.000679</td>\n",
       "      <td>-0.036466</td>\n",
       "      <td>0.017879</td>\n",
       "      <td>0.029082</td>\n",
       "      <td>0.264787</td>\n",
       "      <td>-0.568965</td>\n",
       "      <td>-1.104556</td>\n",
       "      <td>-0.420728</td>\n",
       "      <td>-0.099655</td>\n",
       "      <td>0.114703</td>\n",
       "      <td>-0.151046</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.048472</td>\n",
       "      <td>-1.265161</td>\n",
       "      <td>1.072221</td>\n",
       "      <td>-0.212000</td>\n",
       "      <td>-1.654114</td>\n",
       "      <td>0.026334</td>\n",
       "      <td>-1.258235</td>\n",
       "      <td>0.132185</td>\n",
       "      <td>1.439895</td>\n",
       "      <td>0.081351</td>\n",
       "      <td>0.303468</td>\n",
       "      <td>-3.835013</td>\n",
       "      <td>0.090920</td>\n",
       "      <td>1.136912</td>\n",
       "      <td>0.087297</td>\n",
       "      <td>0.964260</td>\n",
       "      <td>1.429200</td>\n",
       "      <td>-0.953425</td>\n",
       "      <td>-0.134306</td>\n",
       "      <td>0.166052</td>\n",
       "      <td>0.247930</td>\n",
       "      <td>0.671638</td>\n",
       "      <td>-0.162224</td>\n",
       "      <td>0.035976</td>\n",
       "      <td>0.249529</td>\n",
       "      <td>-0.064471</td>\n",
       "      <td>0.001771</td>\n",
       "      <td>0.036109</td>\n",
       "      <td>0.240486</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.121653</td>\n",
       "      <td>-1.174442</td>\n",
       "      <td>0.047953</td>\n",
       "      <td>-0.866262</td>\n",
       "      <td>-1.669277</td>\n",
       "      <td>-0.509637</td>\n",
       "      <td>-1.384852</td>\n",
       "      <td>0.012679</td>\n",
       "      <td>0.475191</td>\n",
       "      <td>0.720227</td>\n",
       "      <td>-1.219198</td>\n",
       "      <td>-0.176240</td>\n",
       "      <td>0.231938</td>\n",
       "      <td>-0.464340</td>\n",
       "      <td>0.740662</td>\n",
       "      <td>-0.733372</td>\n",
       "      <td>-0.348401</td>\n",
       "      <td>1.323356</td>\n",
       "      <td>-0.832835</td>\n",
       "      <td>-0.564935</td>\n",
       "      <td>-0.357383</td>\n",
       "      <td>-0.425196</td>\n",
       "      <td>0.413688</td>\n",
       "      <td>-0.099727</td>\n",
       "      <td>-0.834693</td>\n",
       "      <td>1.115626</td>\n",
       "      <td>-0.035396</td>\n",
       "      <td>-0.044508</td>\n",
       "      <td>-0.313249</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.525014</td>\n",
       "      <td>0.995277</td>\n",
       "      <td>-0.295979</td>\n",
       "      <td>-0.998911</td>\n",
       "      <td>1.207546</td>\n",
       "      <td>-0.215760</td>\n",
       "      <td>1.125052</td>\n",
       "      <td>-0.307709</td>\n",
       "      <td>0.543482</td>\n",
       "      <td>0.510527</td>\n",
       "      <td>-1.351173</td>\n",
       "      <td>0.012369</td>\n",
       "      <td>0.561424</td>\n",
       "      <td>-0.420122</td>\n",
       "      <td>-0.216693</td>\n",
       "      <td>-0.043314</td>\n",
       "      <td>-0.812874</td>\n",
       "      <td>-0.672758</td>\n",
       "      <td>0.105501</td>\n",
       "      <td>0.264004</td>\n",
       "      <td>-0.433079</td>\n",
       "      <td>-0.711576</td>\n",
       "      <td>0.121702</td>\n",
       "      <td>-0.031637</td>\n",
       "      <td>-0.269392</td>\n",
       "      <td>0.130860</td>\n",
       "      <td>0.195777</td>\n",
       "      <td>-0.010006</td>\n",
       "      <td>-0.312289</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.952819</td>\n",
       "      <td>-1.108360</td>\n",
       "      <td>-0.532308</td>\n",
       "      <td>-0.379013</td>\n",
       "      <td>-1.052130</td>\n",
       "      <td>-0.055873</td>\n",
       "      <td>-0.981905</td>\n",
       "      <td>0.188208</td>\n",
       "      <td>0.126116</td>\n",
       "      <td>0.834314</td>\n",
       "      <td>0.420594</td>\n",
       "      <td>0.033348</td>\n",
       "      <td>-1.311615</td>\n",
       "      <td>0.382533</td>\n",
       "      <td>0.005912</td>\n",
       "      <td>-1.047495</td>\n",
       "      <td>-0.438412</td>\n",
       "      <td>1.798047</td>\n",
       "      <td>-0.517892</td>\n",
       "      <td>-0.581788</td>\n",
       "      <td>-0.524218</td>\n",
       "      <td>-1.185909</td>\n",
       "      <td>0.471540</td>\n",
       "      <td>0.626387</td>\n",
       "      <td>-0.640573</td>\n",
       "      <td>-0.718092</td>\n",
       "      <td>0.026179</td>\n",
       "      <td>-0.023002</td>\n",
       "      <td>-0.093194</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -0.572468  0.278829  0.357892 -1.432970 -0.106104  1.643718 -0.509810   \n",
       "1  1.048472 -1.265161  1.072221 -0.212000 -1.654114  0.026334 -1.258235   \n",
       "2  2.121653 -1.174442  0.047953 -0.866262 -1.669277 -0.509637 -1.384852   \n",
       "3 -0.525014  0.995277 -0.295979 -0.998911  1.207546 -0.215760  1.125052   \n",
       "4  1.952819 -1.108360 -0.532308 -0.379013 -1.052130 -0.055873 -0.981905   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V13       V14  \\\n",
       "0  0.763207 -0.937081  0.005115 -0.741923 -0.203978  0.674906 -0.337470   \n",
       "1  0.132185  1.439895  0.081351  0.303468 -3.835013  0.090920  1.136912   \n",
       "2  0.012679  0.475191  0.720227 -1.219198 -0.176240  0.231938 -0.464340   \n",
       "3 -0.307709  0.543482  0.510527 -1.351173  0.012369  0.561424 -0.420122   \n",
       "4  0.188208  0.126116  0.834314  0.420594  0.033348 -1.311615  0.382533   \n",
       "\n",
       "        V15       V16       V17       V18       V19       V20       V21  \\\n",
       "0  0.491004 -0.197214  1.496023 -2.785659  1.000679 -0.036466  0.017879   \n",
       "1  0.087297  0.964260  1.429200 -0.953425 -0.134306  0.166052  0.247930   \n",
       "2  0.740662 -0.733372 -0.348401  1.323356 -0.832835 -0.564935 -0.357383   \n",
       "3 -0.216693 -0.043314 -0.812874 -0.672758  0.105501  0.264004 -0.433079   \n",
       "4  0.005912 -1.047495 -0.438412  1.798047 -0.517892 -0.581788 -0.524218   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0  0.029082  0.264787 -0.568965 -1.104556 -0.420728 -0.099655  0.114703   \n",
       "1  0.671638 -0.162224  0.035976  0.249529 -0.064471  0.001771  0.036109   \n",
       "2 -0.425196  0.413688 -0.099727 -0.834693  1.115626 -0.035396 -0.044508   \n",
       "3 -0.711576  0.121702 -0.031637 -0.269392  0.130860  0.195777 -0.010006   \n",
       "4 -1.185909  0.471540  0.626387 -0.640573 -0.718092  0.026179 -0.023002   \n",
       "\n",
       "     Amount  Class  \n",
       "0 -0.151046      0  \n",
       "1  0.240486      0  \n",
       "2 -0.313249      0  \n",
       "3 -0.312289      0  \n",
       "4 -0.093194      0  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "29962f7f-f7a9-44df-a111-dd6ebee6c674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    473\n",
       "1    473\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "839a997a-8278-4213-baa8-f9ca49b76c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = new_data.drop('Class' , axis = 1)\n",
    "Y = new_data['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5dad58bd-648f-417c-a86e-c56b44810b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train , X_test , Y_train , Y_test = train_test_split(X , Y , test_size = 0.2 , random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "789f6424-5fa7-4696-a672-dcdb2c181e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============Logistic Regression===============\n",
      "\n",
      " Accuracy: 0.9473684210526315\n",
      "\n",
      " Precision: 0.9791666666666666\n",
      "\n",
      " Recall: 0.9215686274509803\n",
      "\n",
      " F1 Score: 0.9494949494949495\n",
      "\n",
      "=============Decision Tree Classifier===============\n",
      "\n",
      " Accuracy: 0.9210526315789473\n",
      "\n",
      " Precision: 0.9223300970873787\n",
      "\n",
      " Recall: 0.9313725490196079\n",
      "\n",
      " F1 Score: 0.926829268292683\n"
     ]
    }
   ],
   "source": [
    "classifier = {\n",
    "    \"Logistic Regression\": LogisticRegression() ,\n",
    "    \"Decision Tree Classifier\": DecisionTreeClassifier()\n",
    "}\n",
    "for name , clf in classifier.items():\n",
    "    print(f\"\\n============={name}===============\")\n",
    "    clf.fit(X_train , Y_train)\n",
    "    Y_pred = clf.predict(X_test)\n",
    "    print(f\"\\n Accuracy: {accuracy_score(Y_test , Y_pred)}\")\n",
    "    print(f\"\\n Precision: {precision_score(Y_test , Y_pred)}\")\n",
    "    print(f\"\\n Recall: { recall_score(Y_test , Y_pred)}\")\n",
    "    print(f\"\\n F1 Score: {f1_score(Y_test , Y_pred)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "94bee1f6-d568-4693-a919-8e8dc3721611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see we did undersampling to balance our data so we got improvements in our F1 Score and other measurements as well\n",
    "# Now , oversampling \n",
    "# Method used : SMOTE\n",
    "X = data.drop('Class' , axis = 1 )\n",
    "Y = data['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4f9615ff-7409-437b-b41e-b32254ac35d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(275663, 29)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c7db84c0-a6b5-41d0-806c-cd3384520735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(275663,)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6779fc9f-4a93-4870-ba06-adc8a9431c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "474f22ae-89b0-44a1-9ee9-bb14d1f1c31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_res , Y_res = SMOTE().fit_resample(X , Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "04915553-70ab-4cd8-9180-b810b28eebb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    275190\n",
       "1    275190\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_res.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3601b3d7-2c91-4f9c-9911-4fc1ed059d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now as we can see we have much more balanced amount of data for fraud and non fraud transactions \n",
    "#we can now simply apply the machine learning algorithms \n",
    "X_train , X_test , Y_train , Y_test = train_test_split(X_res , Y_res , test_size = 0.2 , random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "44a70f03-aa79-4e93-97c7-759719204305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============Logistic Regression===============\n",
      "\n",
      " Accuracy: 0.9452923434717831\n",
      "\n",
      " Precision: 0.9727987026776579\n",
      "\n",
      " Recall: 0.9161318473537807\n",
      "\n",
      " F1 Score: 0.943615288103219\n",
      "\n",
      "=============Decision Tree Classifier===============\n",
      "\n",
      " Accuracy: 0.9982466659398961\n",
      "\n",
      " Precision: 0.9977659110723627\n",
      "\n",
      " Recall: 0.9987273421449739\n",
      "\n",
      " F1 Score: 0.9982463951153472\n"
     ]
    }
   ],
   "source": [
    "classifier = {\n",
    "    \"Logistic Regression\": LogisticRegression() ,\n",
    "    \"Decision Tree Classifier\": DecisionTreeClassifier()\n",
    "}\n",
    "for name , clf in classifier.items():\n",
    "    print(f\"\\n============={name}===============\")\n",
    "    clf.fit(X_train , Y_train)\n",
    "    Y_pred = clf.predict(X_test)\n",
    "    print(f\"\\n Accuracy: {accuracy_score(Y_test , Y_pred)}\")\n",
    "    print(f\"\\n Precision: {precision_score(Y_test , Y_pred)}\")\n",
    "    print(f\"\\n Recall: { recall_score(Y_test , Y_pred)}\")\n",
    "    print(f\"\\n F1 Score: {f1_score(Y_test , Y_pred)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3ad7f567-18a6-423e-83e8-3d6b5bfcadfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>DecisionTreeClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.tree.DecisionTreeClassifier.html\">?<span>Documentation for DecisionTreeClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>DecisionTreeClassifier()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Saving model\n",
    "dtc = DecisionTreeClassifier()\n",
    "dtc.fit(X_res , Y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "28168463-89cd-4a1c-b2ae-5a9236e1f180",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "435bc129-0b22-4827-af87-f3691a7cccc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['credit_card_model.pkl']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(dtc,\"credit_card_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "65e3da6b-aace-40b7-b3c9-882973e68057",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load(\"credit_card_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0af34fd1-5dde-4d2a-a868-b116753bbaa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#yaha par jo code likha h ye .pkl file se values cpy paste se hoga\n",
    "pred = model.predict([[\n",
    "    -1.3598071336738, -0.0727811733098497, 2.53634673796914, 1.37815522427443, -0.338320769942518,\n",
    "    0.462387777762292, 0.239598554061257, 0.0986979012610507, 0.363786969611213, 0.0907941719789316,\n",
    "    -0.551599533260813, -0.617800855762348, -0.991389847235408, -0.311169353699879, 1.46817697209427,\n",
    "    -0.470400525259478, 0.207971241929242, 0.0257905801985591, 0.403992960255733, 0.251412098239705,\n",
    "    -0.018306777944153, 0.277837575558899, -0.110473910188767, 0.0669280749146731, 0.128539358273528,\n",
    "    -0.189114843888824, 0.133558376740387, -0.0210530534538215, 149.62\n",
    "]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ccfe5314-460c-4272-838b-65f572bc2b09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d7448f10-e13d-4f74-aeb8-dfae68d87086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal Transaction\n"
     ]
    }
   ],
   "source": [
    "if pred[0] == 0 :\n",
    "    print (\"Normal Transaction\")\n",
    "else:\n",
    "    print(\"Fraud Transaction\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1617ae6d-c965-4444-b752-a8b2fb7dad4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
